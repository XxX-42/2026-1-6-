% 1_background.tex - 课题背景与意义

\section{课题背景与意义}

\subsection{研究背景}
随着移动互联网的高速发展，\textbf{短视频平台用户规模已突破10亿}，以抖音、快手、B站为代表的内容平台每日产生海量多模态数据。传统的\textbf{单模态情感分析}方法在面对复杂语义时暴露出显著局限性：

\begin{itemize}
    \item \textbf{文本模态局限}：纯文本难以准确识别\textbf{反讽}（如"真是太棒了"的负面含义）与\textbf{双关}等修辞手法，缺乏语气、表情等辅助信息。
    \item \textbf{视觉模态局限}：单纯的面部表情识别在非受控环境下易受光照、遮挡影响，且无法区分"职业微笑"与真实情感。
    \item \textbf{声学模态局限}：孤立的语音信号难以判断说话者的真实意图，尤其在背景噪声干扰时鲁棒性较差。
\end{itemize}

一个典型案例是中文语境下的\textbf{"笑哭"表情（😂）}：用户常以此表达无奈、嘲讽甚至悲伤，与字面"笑"的含义形成矛盾。单一信息源无法解析这种\textbf{跨模态语义冲突}，导致情感判断失误。

\subsection{研究意义}
本课题通过融合\textbf{文本、视觉、声学三通道}信息，旨在解决上述单模态瓶颈，具有以下核心价值：

\begin{enumerate}
    \item \textbf{互补性验证}：当某一模态信息模糊时（如文字反讽），其他模态（如语气愤怒、表情严肃）可提供印证，消除歧义。
    \item \textbf{鲁棒性提升}：多通道冗余设计使模型在部分信息缺失（如视频无字幕、音频静音）时仍能维持基本判断能力。
    \item \textbf{应用场景广泛}：研究成果可直接应用于\textbf{舆情监控}（识别网络负面情绪）、\textbf{智能客服}（判断用户满意度）及\textbf{人机交互}（情感陪伴机器人）等领域。
\end{enumerate}
