% 1_background.tex - 课题背景与意义

\section{课题背景与意义}

\subsection{研究背景}

随着移动互联网与 5G 技术的深度普及，以抖音、快手、B站为代表的短视频平台用户规模已突破十亿量级，人们的情感表达方式也从单一的文字评论演变为融合表情包、语音弹幕与面部反应的多模态形式。然而，传统的情感分析技术仍以\textbf{单模态文本处理}为主导，这在面对中文互联网中高度复杂的表达习惯时显得力不从心。

一个典型的困境是：当用户发送"你真行"这句话并配上一个翻白眼的表情包时，纯文本模型几乎必然将其误判为积极情感——因为从字面语义看，"你真行"本身确实是一句肯定的表述。然而任何中文母语者都能轻易识别出，这其实是一种典型的\textbf{反讽}表达。类似的案例在中文网络空间中俯拾皆是：B站弹幕中的"友军厚葬"看似在赞美队友，实则暗含嘲讽；微信聊天中的"笑哭"表情（😂）更是常被用于表达无奈甚至悲伤，与其字面"大笑"的含义形成诡异的背离。这些现象揭示了一个核心问题：\textbf{当语言本身充满歧义时，仅凭文本信息无法还原说话者的真实意图}。

与此同时，当前高质量的多模态情感数据集主要以英文为主，如 CMU-MOSI 和 CMU-MOSEI，而中文在语义结构、谐音梗使用以及四声调韵律上与英文存在根本性差异。这意味着直接迁移国外预训练模型往往效果欠佳，也凸显了构建适配中文语境的多模态分析方案的紧迫性。

\subsection{研究意义}

本课题的核心价值在于通过引入\textbf{视觉与声学模态}，为文本语义歧义提供额外的消歧依据。具体而言，当文字表达模糊时，说话者的面部表情（皱眉、撇嘴）与语音语调（尖锐、低沉）往往能够暴露其真实情感倾向。这种\textbf{模态间的互补性}正是多模态分析相较于单模态方法的本质优势所在。

此外，多通道架构还具备天然的\textbf{鲁棒性}：在实际应用场景中，视频可能存在静音片段、无字幕或人脸遮挡等情况，多模态系统可以依赖剩余模态维持基本判断能力，而单模态系统在信息缺失时往往直接失效。从应用层面看，本课题的成果可直接服务于舆情监控系统的情感预警、智能客服的满意度评估以及人机交互中的情绪感知模块，具有切实的工程落地价值。
