% 2_research_status.tex - 国内外研究现状

\section{国内外研究现状}

多模态情感分析并非一蹴而就，其技术演进经历了从简单到复杂、再到务实回归的曲折历程。早期研究者受限于模型表达能力，普遍采用\textbf{Early Fusion}策略：将各模态的手工特征（如文本的词袋向量、视觉的 HOG 描述子、声学的 MFCC 系数）直接拼接成高维向量，送入 SVM 或逻辑回归进行分类。这一方法实现简单，却几乎完全忽略了模态间的交互关系。随后，研究者开始探索更复杂的融合机制：Zadeh 等人提出的 \textbf{Tensor Fusion Network} 通过外积运算捕捉模态间的高阶交互，\textbf{Memory Fusion Network} 则引入了记忆单元建模时序依赖。然而，这些张量方法在提升性能的同时也带来了参数爆炸的副作用，模型规模迅速膨胀。

进入预训练大模型时代后，基于 \textbf{Transformer} 的架构成为主流：BERT 及其中文变体在文本语义理解上取得突破，ViT 将图像建模为 Patch 序列打破了 CNN 的垄断，CLIP 更是实现了视觉与语言的跨模态对齐。这些预训练模型为多模态任务提供了强大的特征提取器，但一个常被忽视的事实是——\textbf{这些模型的训练与推理对算力的要求极高}。以联合微调 BERT 与 ResNet 为例，其显存占用通常超过 12GB，这在科研机构的 A100 集群上或许不成问题，但对于使用 RTX 3060（6GB 显存）的本科毕设环境而言，几乎意味着无法运行。

与此同时，当前主流研究多基于英文数据集 CMU-MOSI 进行实验，而中文语境存在独特的挑战：四声调的韵律变化对情感判断有显著影响，网络流行语与谐音梗的使用极为普遍，"阴阳怪气"的表达方式更是难以被字面语义捕捉。国内虽有学者开始关注这一问题，但高质量的中文多模态数据依然稀缺。清华大学于 2020 年发布的 \textbf{CH-SIMS} 数据集是目前为数不多的选择，其样本来源于非受控的影视片段，包含背景杂音、人脸遮挡等真实噪声，这既是挑战，也为模型鲁棒性的验证提供了理想的试验场。

基于上述分析，本课题明确选择\textbf{回归 Early Fusion 的务实路线}：通过冻结 BERT 与 ResNet 的骨干参数、仅训练分类头的方式，将显存需求压缩至 6GB 以内；同时采用梯度累积策略模拟大批量训练。这一工程导向的设计并非对 SOTA 的盲目追逐，而是在有限资源约束下追求\textbf{性价比最高的可落地方案}——这恰恰是本科毕业设计应有的务实态度。
