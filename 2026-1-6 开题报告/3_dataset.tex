% 3_dataset.tex - 数据集介绍

\section{数据集介绍}

\subsection{CH-SIMS 数据集选用分析}

在多模态情感分析领域，目前主流的数据集如 CMU-MOSI 和 CMU-MOSEI 均基于英语语料，而高质量的中文多模态情感数据集相对匮乏。直到 2020 年，清华大学发布了 \textbf{CH-SIMS} (Chinese Single- and Multi-modal Sentiment Analysis) 数据集，才为该领域提供了重要的中文基准。

CH-SIMS 的样本来源于\textbf{电影、电视剧、综艺节目}等非受控环境，共计 2,281 个视频片段。与实验室受控采集的数据相比，这种自然场景下的数据虽然能够更真实地反映人类情感表达，但也引入了复杂的噪声，如背景音乐干扰、非正面人脸、光照变化等。从工程实践的角度来看，这些挑战恰好能够检验模型在实际应用中的鲁棒性。

该数据集将样本划分为训练集 1,368 例、验证集 456 例与测试集 457 例。值得注意的是，CH-SIMS 提供了\textbf{三模态独立标注}，即文本、视觉、声学三个模态分别拥有独立的情感标签。这一特性使得我们能够在消融实验中精确量化各模态的贡献，并深入研究模态间的不一致性（例如文本积极但语气消极的"模态冲突"现象）。

\subsection{类别不平衡问题的处理}

通过对训练集分布的统计分析，我们发现正、中、负三类样本的分布存在显著的不平衡现象，负面与中性样本的数量多于正面样本。若直接使用标准的交叉熵损失函数进行训练，模型可能会倾向于预测多数类以降低整体损失，从而忽略少数类样本的学习。

为了解决这一问题，我们在损失函数中引入了\textbf{类别权重（Class Weights）}策略。具体而言，为样本量较少的类别分配更高的权重系数，增加其在损失计算中的比重，从而引导模型均衡学习各类情感特征。这一策略在不增加并造成过拟合风险的前提下，有效地缓解了类别不平衡带来的负面影响。

\subsection{数据预处理与噪声处理}

鉴于 CH-SIMS 数据集的非受控特性，我们在训练前构建了一套完整的数据清洗管线，以消除噪声对模型性能的影响。面对原始数据中存在的无效帧问题，MTCNN 算法被部署用于人脸检测与过滤；在处理过程中，约有 8\% 的视频帧因背对镜头或遮挡导致无法检测到有效人脸，针对这些样本，我们选择将其直接剔除以保证输入数据质量。针对剪辑转场常见的全黑画面，我们引入了基于像素方差的黑帧过滤机制，自动识别并移除低方差的无效帧，防止其干扰特征提取。在此基础上，声学模态的处理聚焦于静音片段的干扰，通过计算均方根（RMS）能量筛选出低能量片段，并在后续训练中对其进行掩码（Mask）处理。上述清洗步骤完成后，利用 CH-SIMS 提供的词级对齐信息，视频帧序列与音频片段被精确对齐至文本的词级粒度，从而确保了多模态特征在时序上的严格一致性。
