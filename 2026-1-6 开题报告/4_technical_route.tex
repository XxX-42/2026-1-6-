% 4_technical_route.tex - 核心技术路线

\section{核心技术路线}

\subsection{总体架构设计}

本研究采用\textbf{三塔架构 (Three-Tower Architecture)} 进行多模态特征提取，并通过\textbf{Early Fusion（特征级拼接）}实现模态融合。该方案遵循"分而治之"的设计哲学：

\begin{quote}
\textbf{设计理念}：三路独立编码 $\rightarrow$ 特征拼接 $\rightarrow$ 联合分类
\end{quote}

相比复杂的张量融合或跨模态注意力机制，Early Fusion 具有以下\textbf{工程优势}：
\begin{itemize}
    \item \textbf{结构简洁}：各模态编码器独立，易于调试与维护。
    \item \textbf{显存可控}：无需存储高阶交互张量，适合在消费级 GPU 上运行。
    \item \textbf{可解释性}：通过消融实验可清晰量化各模态的贡献。
\end{itemize}

\subsection{文本塔 (Text Tower)}

\subsubsection{模型选择}

采用 \textbf{\texttt{bert-base-chinese}} 预训练模型（由 Google 发布，HuggingFace 托管），该模型在大规模中文语料上进行了 Masked Language Model 预训练，具备强大的中文语义理解能力。

\subsubsection{特征提取流程}

\begin{enumerate}
    \item 将输入文本经 \textbf{BertTokenizer} 分词，添加 [CLS] 和 [SEP] 特殊标记。
    \item 将 Token 序列送入 BERT 编码器，经过 12 层 Transformer Block。
    \item 取最后一层的 \textbf{[CLS] token 隐藏状态}作为句级语义表示。
\end{enumerate}

\subsubsection{输出规格}

$$\mathbf{T} \in \mathbb{R}^{768}$$

其中 768 为 BERT-base 的隐藏层维度。

\subsection{视觉塔 (Visual Tower)}

\subsubsection{人脸预处理}

使用 \textbf{MTCNN} 进行人脸检测与关键点定位：
\begin{itemize}
    \item 检测人脸边界框 (Bounding Box)。
    \item 提取 \textbf{5 点面部关键点}：双眼中心、鼻尖、左右嘴角。
    \item 基于关键点进行\textbf{仿射变换}，将人脸归一化至 $224 \times 224$。
\end{itemize}

\subsubsection{特征提取}

将对齐后的人脸帧序列送入预训练的 \textbf{ResNet-50} \cite{resnet}（在 ImageNet 上预训练），提取每帧的高层视觉特征：
\begin{itemize}
    \item 移除 ResNet 的最后全连接层，取 \textbf{AvgPool 输出}作为帧级特征。
    \item 每帧输出 \textbf{2048 维}特征向量。
\end{itemize}

\subsubsection{时序聚合}

对视频片段内的 $N$ 帧特征进行\textbf{时序均值池化 (Temporal Mean Pooling)}：

\begin{equation}
    \mathbf{V} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{v}_i
\end{equation}

其中 $\mathbf{v}_i \in \mathbb{R}^{2048}$ 为第 $i$ 帧的 ResNet 输出。

\textbf{设计说明}：采用均值池化而非循环网络（LSTM/GRU）的原因是：
\begin{itemize}
    \item \textbf{显存节约}：均值池化无可训练参数，显著降低显存占用。
    \item \textbf{计算高效}：避免序列依赖的反向传播，加速训练。
    \item \textbf{鲁棒性}：对帧数变化不敏感，自动适应不同长度的视频。
\end{itemize}

\subsubsection{输出规格}

$$\mathbf{V} \in \mathbb{R}^{2048}$$

\subsection{声学塔 (Acoustic Tower)}

\subsubsection{特征提取}

使用 \textbf{OpenSMILE} \cite{opensmile} 提取帧级声学特征，主要包括：
\begin{itemize}
    \item \textbf{MFCC}：39 维（13 维静态 + $\Delta$ + $\Delta\Delta$）
    \item \textbf{Chroma}：12 维
    \item \textbf{Energy / Pitch}：韵律特征
\end{itemize}

\subsubsection{时序编码}

将帧级声学特征序列送入 \textbf{一维卷积网络 (Conv1D)}：
\begin{itemize}
    \item \textbf{Conv1D}：提取局部时序模式，捕捉语音中的短时情感波动。
    \item \textbf{ReLU 激活}：引入非线性。
    \item \textbf{MeanPool}：对时序维度进行均值池化，输出固定长度向量。
\end{itemize}

\subsubsection{输出规格}

$$\mathbf{A} \in \mathbb{R}^{256}$$

\subsection{模态融合与分类}

\subsubsection{Early Fusion 拼接}

将三塔输出在特征维度上\textbf{直接拼接 (Concatenation)}：

\begin{equation}
    \mathbf{F} = [\mathbf{T}; \mathbf{V}; \mathbf{A}] \in \mathbb{R}^{768 + 2048 + 256} = \mathbb{R}^{3072}
\end{equation}

\subsubsection{分类头}

\begin{enumerate}
    \item \textbf{Dropout}：$p = 0.3$，随机丢弃神经元以防止过拟合。
    \item \textbf{全连接层}：$\text{FC}: \mathbb{R}^{3072} \rightarrow \mathbb{R}^{C}$，其中 $C$ 为类别数。
    \item \textbf{Softmax}：输出各类别的概率分布。
\end{enumerate}

\subsubsection{损失函数}

采用\textbf{加权交叉熵损失 (Weighted Cross-Entropy)}：

\begin{equation}
    \mathcal{L} = -\sum_{c=1}^{C} w_c \cdot y_c \log(\hat{y}_c)
\end{equation}

其中 $w_c$ 为类别权重，用于缓解数据不平衡问题。

\subsection{硬件适配与显存优化}

本项目的开发环境为 \textbf{RTX 3060 Laptop GPU (6GB 显存)}，为确保模型可在该配置下顺利训练，采用以下\textbf{轻量化策略}：

\subsubsection{梯度累积 (Gradient Accumulation)}

将逻辑 Batch Size 拆分为多个小批次：
\begin{itemize}
    \item 设物理 Batch Size = 4，累积步数 = 8。
    \item 等效 Batch Size = $4 \times 8 = 32$。
    \item 每 8 步执行一次参数更新，显存峰值仅需容纳 4 个样本。
\end{itemize}

\subsubsection{冻结骨干网络 (Freeze Backbone)}

\begin{itemize}
    \item \textbf{第一阶段}：冻结 BERT 和 ResNet 的全部参数，仅训练分类头与声学塔。
    \item \textbf{第二阶段}：解冻顶层（如 BERT 最后 2 层），进行端到端微调。
\end{itemize}

该策略可将可训练参数量从约 1.5 亿降至约 500 万，显存占用降低 70\% 以上。

\subsubsection{混合精度训练 (FP16)}

使用 PyTorch AMP (Automatic Mixed Precision)：
\begin{itemize}
    \item 前向传播使用 FP16，反向传播自动缩放梯度。
    \item 在保持训练精度的前提下，显存消耗降低约 30\%--50\%。
\end{itemize}
