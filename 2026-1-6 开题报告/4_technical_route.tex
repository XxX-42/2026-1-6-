% 4_technical_route.tex - 核心技术路线

\section{核心技术路线}

\subsection{架构设计与资源约束}

本研究在设计模型架构时，充分考虑了硬件环境的限制，即需要在 \textbf{RTX 3060 Laptop（6GB 显存）} 上完成模型的训练与推理。这意味着高计算复杂度和高显存占用的模型（如大规模张量融合网络、端到端微调的跨模态 Transformer）难以直接部署。

鉴于此，我们采用了工程上更为可行的\textbf{三塔架构（Three-Tower Architecture）结合早期融合（Early Fusion）}方案。如图 \ref{fig:three_tower} 所示，在该架构中，文本、视觉、声学三个模态分别通过独立的编码器提取特征，随后将特征向量进行拼接，并送入共享的分类器进行预测。图中 ❄️ 标志清晰地标识了哪些骨干网络（BERT 与 ResNet）被冻结以节省显存，而最终的 3072 维拼接向量（768 + 2048 + 256）则体现了我们"先提取、后融合"的设计哲学。这种设计在保证基本多模态交互能力的同时，显著降低了显存占用和计算开销，符合本科毕业设计的实际硬件条件。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{Snipaste_2026-01-06_10-59-47.png}
    \caption{基于三塔架构的多模态情感分析模型总体框图}
    \label{fig:three_tower}
\end{figure}

\subsection{文本塔设计}

在文本特征提取方面，我们利用了 HuggingFace 提供的 \textbf{\texttt{bert-base-chinese}} 预训练模型。该模型基于大规模中文语料训练，具备强大的语义理解能力。如图 \ref{fig:three_tower} 左侧所示，文本输入经过 Tokenizer 处理后进入 BERT 编码器，最终输出 768 维的 [CLS] 向量。

具体处理流程如下：利用 BertTokenizer 对输入文本进行分词，并添加 [CLS] 与 [SEP] 标记；随后将序列输入 BERT 的 12 层 Transformer 编码器。最终，我们选取最后一层的 \textbf{[CLS] 向量}（768 维）作为句子的全局语义表征。由于 [CLS] 标记在预训练阶段已被专门训练用于聚合序列信息，因此直接作为句子表示是标准且有效的做法。值得注意的是，如图中 ❄️ 标志所示，BERT 的骨干参数在训练初期被冻结，仅在后期解冻顶层进行微调。

\subsection{视觉塔设计与时序聚合}

视觉模态的处理对显存资源的消耗最为显著。如图 \ref{fig:three_tower} 中间所示，视频帧首先经过 MTCNN 进行人脸检测与对齐，随后送入 ResNet-50 提取每帧的 2048 维特征向量。考虑到显存限制，我们并未采用 LSTM 等循环网络进行时序建模，而是使用了图中标注的 \textbf{Mean Pool} 操作，将所有帧特征取平均压缩为单一向量。

为解决时序建模带来的显存压力，我们采用了\textbf{时序均值池化（Temporal Mean Pooling）}策略。对于一个包含 $N$ 帧的视频片段，我们将所有帧的特征向量进行平均：
\begin{equation}
    \mathbf{V} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{v}_i, \quad \mathbf{v}_i \in \mathbb{R}^{2048}
\end{equation}
这一操作将变长的视频序列压缩为固定的 2048 维向量，虽然在一定程度上损失了细粒度的时序动态信息，但有效地控制了显存占用和计算复杂度。同样地，ResNet-50 的骨干参数也被冻结（如图中 ❄️ 所示），仅作为特征提取器使用。

\subsection{声学塔设计}

声学模态的处理采用 \textbf{OpenSMILE} 工具包提取底层声学特征，主要包含 13 维 MFCC（及其一阶、二阶差分）和 12 维 Chroma 特征，共计 51 维。如图 \ref{fig:three_tower} 右侧所示，这些特征经过 Conv1D 网络处理后，同样通过 Mean Pool 聚合为 256 维的固定长度向量。

为了处理变长的声学特征序列，我们设计了一个轻量级的\textbf{一维卷积网络（Conv1D）}。该网络通过卷积操作捕捉局部的时序模式，并通过均值池化将其聚合为 256 维的固定长度向量。这一设计在保留关键声学线索的同时，保持了参数量的轻量化。

\subsection{融合策略}

在获得文本 $\mathbf{T}$、视觉 $\mathbf{V}$ 和声学 $\mathbf{A}$ 三个特征向量后，如图 \ref{fig:three_tower} 底部所示，我们采用\textbf{直接拼接（Concatenation）}的方式进行融合，形成 3072 维的联合表征向量：
\begin{equation}
    \mathbf{F} = [\mathbf{T}; \mathbf{V}; \mathbf{A}] \in \mathbb{R}^{3072}
\end{equation}
拼接后的向量 $\mathbf{F}$ 经过 Dropout ($p=0.3$) 正则化处理，输入全连接层映射至情感类别空间，最后通过 Softmax 函数输出预测概率。图中明确标注了 768 + 2048 + 256 = 3072 的维度构成，体现了各模态特征的贡献比例。

尽管拼接策略相对简单，但在计算资源受限的场景下，它是平衡性能与效率的有效选择。

\subsection{显存优化策略}

为了在 6GB 显存环境下顺利训练 BERT 和 ResNet 主干网络，我们制定了一套层层递进的资源适配方案。面对 BERT 庞大的参数量，我们并未选择全量微调，而是实施了\textbf{冻结骨干网络（Freeze Backbone）}策略，即在训练初期锁定 BERT 和 ResNet 的参数，仅开放分类头和声学网络的梯度更新，待模型收敛后再解冻顶层微调，从而大幅降低显存峰值。在此基础上，为了突破物理显存对 Batch Size 的限制，\textbf{梯度累积（Gradient Accumulation）}技术被应用于训练循环中；该技术通过累积多次前向传播的梯度（例如物理 Batch Size 为 4，累积 8 次）再执行一次参数更新，等效实现了大批量训练的效果。同时，为了进一步压榨硬件性能，\textbf{混合精度训练（FP16）}借助 PyTorch 的 AMP 模块被引入全流程，通过在计算中使用半精度浮点数，不仅显著降低了显存占用，更在保证收敛精度的前提下大幅提升了训练速度。

图 \ref{fig:three_tower} 中的 ❄️ 标志正是这一策略的直观体现：被冻结的 BERT 和 ResNet 不参与梯度计算，从而将可训练参数从约 1.5 亿降至约 500 万，使得整个三塔模型能够在消费级显卡上完成端到端训练。
