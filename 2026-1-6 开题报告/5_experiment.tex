% 5_experiment.tex - 实验设计与预期产出

\section{实验设计与预期产出}

\subsection{消融实验设计}

为系统验证各模态的\textbf{独立贡献}及多模态融合的\textbf{互补效应}，本项目设计以下 \textbf{7 组消融实验 (Ablation Study)}：

\begin{table}[htbp]
\centering
\caption{消融实验配置}
\begin{tabular}{clll}
\toprule
\textbf{序号} & \textbf{实验组} & \textbf{模态组合} & \textbf{验证目标} \\
\midrule
1 & Baseline-T & 仅文本 (Text) & 文本模态独立性能上界 \\
2 & Baseline-V & 仅视觉 (Visual) & 面部表情对情感判断的贡献 \\
3 & Baseline-A & 仅声学 (Acoustic) & 语音韵律对情感判断的贡献 \\
\midrule
4 & Fusion-TV & 文本 + 视觉 & T-V 互补性验证 \\
5 & Fusion-TA & 文本 + 声学 & T-A 互补性验证 \\
6 & Fusion-VA & 视觉 + 声学 & V-A 互补性验证（无文本基线） \\
\midrule
7 & Full Model & 文本 + 视觉 + 声学 & 三模态融合最优性能 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{实验假设}

本项目的核心实验预期在于验证模态间的互补性。具体而言，我们预计全模态模型（Full Model）将在 Accuracy 与 Weighted F1 指标上全面超越所有单模态基线，以此证明多源信息的融合能够有效消除单一视角的歧义。同时，我们推测文本模态在单模态测试中将表现出最强的判别力，验证其在情感分析中的主导地位；而双模态组合（如视觉+声学）的性能表现，则将揭示在缺乏语义信息的情况下，单纯依靠非语言线索（表情与语调）进行情感诊断的可行性边界。

\subsection{评估指标}

\begin{itemize}
    \item \textbf{Accuracy (准确率)}：
    \begin{equation}
        \text{Accuracy} = \frac{\text{正确预测数}}{\text{总样本数}}
    \end{equation}
    衡量模型的整体分类正确率。
    
    \item \textbf{Weighted F1 (加权 F1 值)}：
    \begin{equation}
        \text{Weighted F1} = \sum_{c=1}^{C} \frac{n_c}{N} \cdot F1_c
    \end{equation}
    其中 $n_c$ 为类别 $c$ 的样本数，$N$ 为总样本数。该指标对各类别的 F1 按样本数加权平均，\textbf{更适合评估非平衡数据集}。
\end{itemize}

\subsection{实验环境}

\begin{table}[htbp]
\centering
\caption{实验环境配置}
\begin{tabular}{ll}
\toprule
\textbf{组件} & \textbf{规格} \\
\midrule
GPU & NVIDIA GeForce RTX 3060 Laptop (6GB) \\
CPU & AMD Ryzen 9 5900HX (3.29 GHz) \\
内存 & 64GB DDR4 3200MHz \\
操作系统 & Windows 11 专业版 \\
深度学习框架 & PyTorch 2.0+ \\
预训练模型 & bert-base-chinese, ResNet-50 (ImageNet) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{预期产出}

本项目最终将交付一套完整的 PyTorch 工程源码，包含数据清洗管线、三塔模型实现以及训练评估脚本，并配以详细的文档注释以确保可复现性。此外，为了直观展示模型效果，我们将构建一个基于 Gradio 的交互式演示界面，支持用户上传视频片段并实时可视化情感预测结果与各模态的置信度分布。最终的研究成果将汇总为一篇符合学术规范的毕业论文，详细记录消融实验的数据对比、模态互补性分析以及模型在非平衡数据上的表现，为中文多模态情感分析提供有价值的参考。
